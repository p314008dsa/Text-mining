{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline \n",
    "\n",
    "import gc #Garbage Collector interface\n",
    "from datetime import datetime \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from catboost import CatBoostClassifier\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import datasets\n",
    "data_df = pd.read_excel('/Users/Stylewsxcde991/Desktop/金融科技_文字探勘與機器學習/金融科技Final_project/2019年看門狗資訊事件整理.xlsx',index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_df - rows: 4040  columns: 7\n"
     ]
    }
   ],
   "source": [
    "print(\"data_df - rows:\",data_df.shape[0],\" columns:\", data_df.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>公司簡稱</th>\n",
       "      <th>事件日</th>\n",
       "      <th>TCRI(年/月)</th>\n",
       "      <th>事件強度</th>\n",
       "      <th>大事件類別</th>\n",
       "      <th>小事件類別</th>\n",
       "      <th>事件內容</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>個股代號</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1218</th>\n",
       "      <td>泰山</td>\n",
       "      <td>20190101</td>\n",
       "      <td>6(2018/09)</td>\n",
       "      <td>0</td>\n",
       "      <td>M_經營層</td>\n",
       "      <td>MT06_高管異動</td>\n",
       "      <td>發言人林俐婉內部調動，由江巍峰接任。。</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1503</th>\n",
       "      <td>士電</td>\n",
       "      <td>20190101</td>\n",
       "      <td>4(2018/09)</td>\n",
       "      <td>0</td>\n",
       "      <td>M_經營層</td>\n",
       "      <td>MT06_高管異動</td>\n",
       "      <td>內部稽核主管林志強內部調動，由莊文清接任。。</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1504</th>\n",
       "      <td>東元</td>\n",
       "      <td>20190101</td>\n",
       "      <td>4(2018/09)</td>\n",
       "      <td>0</td>\n",
       "      <td>M_經營層</td>\n",
       "      <td>MT06_高管異動</td>\n",
       "      <td>會計主管藍俊雄內部調動，由林鴻名接任。。</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1709</th>\n",
       "      <td>和益</td>\n",
       "      <td>20190101</td>\n",
       "      <td>5(2018/09)</td>\n",
       "      <td>0</td>\n",
       "      <td>M_經營層</td>\n",
       "      <td>MT06_高管異動</td>\n",
       "      <td>內部稽核主管游本詮內部調動，由曾筱茜接任。。</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1721</th>\n",
       "      <td>三晃</td>\n",
       "      <td>20190101</td>\n",
       "      <td>7(2018/09)</td>\n",
       "      <td>0</td>\n",
       "      <td>M_經營層</td>\n",
       "      <td>MT06_高管異動</td>\n",
       "      <td>財務經理洪廷宜內部調動，由王婷渝接任。。</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                公司簡稱       事件日             TCRI(年/月)  事件強度  大事件類別      小事件類別  \\\n",
       "個股代號                                                                           \n",
       "1218  泰山              20190101  6(2018/09)               0  M_經營層  MT06_高管異動   \n",
       "1503  士電              20190101  4(2018/09)               0  M_經營層  MT06_高管異動   \n",
       "1504  東元              20190101  4(2018/09)               0  M_經營層  MT06_高管異動   \n",
       "1709  和益              20190101  5(2018/09)               0  M_經營層  MT06_高管異動   \n",
       "1721  三晃              20190101  7(2018/09)               0  M_經營層  MT06_高管異動   \n",
       "\n",
       "                        事件內容  \n",
       "個股代號                          \n",
       "1218     發言人林俐婉內部調動，由江巍峰接任。。  \n",
       "1503  內部稽核主管林志強內部調動，由莊文清接任。。  \n",
       "1504    會計主管藍俊雄內部調動，由林鴻名接任。。  \n",
       "1709  內部稽核主管游本詮內部調動，由曾筱茜接任。。  \n",
       "1721    財務經理洪廷宜內部調動，由王婷渝接任。。  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 4040 entries, 1218 to 6486\n",
      "Data columns (total 7 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   公司簡稱       3805 non-null   object\n",
      " 1   事件日        4040 non-null   int64 \n",
      " 2   TCRI(年/月)  4040 non-null   object\n",
      " 3   事件強度       4040 non-null   int64 \n",
      " 4   大事件類別      4040 non-null   object\n",
      " 5   小事件類別      4040 non-null   object\n",
      " 6   事件內容       4040 non-null   object\n",
      "dtypes: int64(2), object(5)\n",
      "memory usage: 252.5+ KB\n"
     ]
    }
   ],
   "source": [
    "data_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1    2386\n",
       " 0    1242\n",
       " 1     299\n",
       "-2      80\n",
       "-3      32\n",
       " 3       1\n",
       "Name: 事件強度, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The proportion of each target class\n",
    "\n",
    "data_df[\"事件強度\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Dumping model to file cache /var/folders/xk/80wyspyn4cz5bfm6xr2yw1380000gn/T/jieba.cache\n",
      "Loading model cost 1.198 seconds.\n",
      "Prefix dict has been built successfully.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[pair('我', 'r'),\n",
       " pair('是', 'v'),\n",
       " pair('李孟', 'nr'),\n",
       " pair('，', 'x'),\n",
       " pair('在', 'p'),\n",
       " pair('東京', 'ns'),\n",
       " pair('工作', 'vn'),\n",
       " pair('的', 'uj'),\n",
       " pair('數據', 'n'),\n",
       " pair('科學家', 'n')]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import jieba.posseg as pseg\n",
    "\n",
    "text = '我是李孟，在東京工作的數據科學家'\n",
    "words = pseg.cut(text)\n",
    "[word for word in words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jieba_tokenizer(text):\n",
    "    words = pseg.cut(text)\n",
    "    return ' '.join([\n",
    "        word for word, flag in words if flag != 'x'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'我 是 李孟 在 東京 工作 的 數據 科學家'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jieba_tokenizer(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df['content_tokenized'] = data_df.iloc[:10, 6].apply(jieba_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>公司簡稱</th>\n",
       "      <th>事件日</th>\n",
       "      <th>TCRI(年/月)</th>\n",
       "      <th>事件強度</th>\n",
       "      <th>大事件類別</th>\n",
       "      <th>小事件類別</th>\n",
       "      <th>事件內容</th>\n",
       "      <th>content_tokenized</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>個股代號</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1218</th>\n",
       "      <td>泰山</td>\n",
       "      <td>20190101</td>\n",
       "      <td>6(2018/09)</td>\n",
       "      <td>0</td>\n",
       "      <td>M_經營層</td>\n",
       "      <td>MT06_高管異動</td>\n",
       "      <td>發言人林俐婉內部調動，由江巍峰接任。。</td>\n",
       "      <td>發言 人 林俐婉 內部 調動 由 江巍峰 接任</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1503</th>\n",
       "      <td>士電</td>\n",
       "      <td>20190101</td>\n",
       "      <td>4(2018/09)</td>\n",
       "      <td>0</td>\n",
       "      <td>M_經營層</td>\n",
       "      <td>MT06_高管異動</td>\n",
       "      <td>內部稽核主管林志強內部調動，由莊文清接任。。</td>\n",
       "      <td>內部 稽核 主管 林志強 內部 調動 由 莊文清 接任</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1504</th>\n",
       "      <td>東元</td>\n",
       "      <td>20190101</td>\n",
       "      <td>4(2018/09)</td>\n",
       "      <td>0</td>\n",
       "      <td>M_經營層</td>\n",
       "      <td>MT06_高管異動</td>\n",
       "      <td>會計主管藍俊雄內部調動，由林鴻名接任。。</td>\n",
       "      <td>會計 主管 藍俊雄 內部 調動 由 林鴻名 接任</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1709</th>\n",
       "      <td>和益</td>\n",
       "      <td>20190101</td>\n",
       "      <td>5(2018/09)</td>\n",
       "      <td>0</td>\n",
       "      <td>M_經營層</td>\n",
       "      <td>MT06_高管異動</td>\n",
       "      <td>內部稽核主管游本詮內部調動，由曾筱茜接任。。</td>\n",
       "      <td>內部 稽核 主管 游本 詮內部 調動 由 曾筱茜 接任</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1721</th>\n",
       "      <td>三晃</td>\n",
       "      <td>20190101</td>\n",
       "      <td>7(2018/09)</td>\n",
       "      <td>0</td>\n",
       "      <td>M_經營層</td>\n",
       "      <td>MT06_高管異動</td>\n",
       "      <td>財務經理洪廷宜內部調動，由王婷渝接任。。</td>\n",
       "      <td>財務 經理 洪廷宜 內部 調動 由 王婷渝 接任</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4726</th>\n",
       "      <td>永昕</td>\n",
       "      <td>20190331</td>\n",
       "      <td>7(2018/09)</td>\n",
       "      <td>-1</td>\n",
       "      <td>M_經營層</td>\n",
       "      <td>MT06_高管異動</td>\n",
       "      <td>財務經理陳炯祥離職。。發言人陳炯祥離職。。會計主管陳炯祥離職。。</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4960</th>\n",
       "      <td>誠美材</td>\n",
       "      <td>20190331</td>\n",
       "      <td>D(2019/03)</td>\n",
       "      <td>-2</td>\n",
       "      <td>A_會計/財報分析</td>\n",
       "      <td>AF09_非無保留意見</td>\n",
       "      <td>誠美材 2018年度會計師出具保留意見加繼續經營有關之重大不確定性段落之查核報告：誠美材截至...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5481</th>\n",
       "      <td>新華</td>\n",
       "      <td>20190331</td>\n",
       "      <td>8(2018/09)</td>\n",
       "      <td>-1</td>\n",
       "      <td>M_經營層</td>\n",
       "      <td>MT06_高管異動</td>\n",
       "      <td>總經理陳聖中離職。。</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6235</th>\n",
       "      <td>華孚</td>\n",
       "      <td>20190331</td>\n",
       "      <td>6(2018/09)</td>\n",
       "      <td>-2</td>\n",
       "      <td>M_經營層</td>\n",
       "      <td>MC03_工安議題</td>\n",
       "      <td>1.華孚科技之大陸子公司昆山漢鼎精密金屬有限公司於今日上午於CNC車間西北側因不明原因發生爆...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6486</th>\n",
       "      <td>互動</td>\n",
       "      <td>20190331</td>\n",
       "      <td>6(2018/09)</td>\n",
       "      <td>-1</td>\n",
       "      <td>M_經營層</td>\n",
       "      <td>MT06_高管異動</td>\n",
       "      <td>總經理郭俊良離職。。發言人郭俊良離職。。</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4040 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                公司簡稱       事件日             TCRI(年/月)  事件強度      大事件類別  \\\n",
       "個股代號                                                                    \n",
       "1218  泰山              20190101  6(2018/09)               0      M_經營層   \n",
       "1503  士電              20190101  4(2018/09)               0      M_經營層   \n",
       "1504  東元              20190101  4(2018/09)               0      M_經營層   \n",
       "1709  和益              20190101  5(2018/09)               0      M_經營層   \n",
       "1721  三晃              20190101  7(2018/09)               0      M_經營層   \n",
       "...              ...       ...                   ...   ...        ...   \n",
       "4726  永昕              20190331  7(2018/09)              -1      M_經營層   \n",
       "4960   誠美材            20190331  D(2019/03)              -2  A_會計/財報分析   \n",
       "5481  新華              20190331  8(2018/09)              -1      M_經營層   \n",
       "6235  華孚              20190331  6(2018/09)              -2      M_經營層   \n",
       "6486  互動              20190331  6(2018/09)              -1      M_經營層   \n",
       "\n",
       "            小事件類別                                               事件內容  \\\n",
       "個股代號                                                                   \n",
       "1218    MT06_高管異動                                發言人林俐婉內部調動，由江巍峰接任。。   \n",
       "1503    MT06_高管異動                             內部稽核主管林志強內部調動，由莊文清接任。。   \n",
       "1504    MT06_高管異動                               會計主管藍俊雄內部調動，由林鴻名接任。。   \n",
       "1709    MT06_高管異動                             內部稽核主管游本詮內部調動，由曾筱茜接任。。   \n",
       "1721    MT06_高管異動                               財務經理洪廷宜內部調動，由王婷渝接任。。   \n",
       "...           ...                                                ...   \n",
       "4726    MT06_高管異動                   財務經理陳炯祥離職。。發言人陳炯祥離職。。會計主管陳炯祥離職。。   \n",
       "4960  AF09_非無保留意見  誠美材 2018年度會計師出具保留意見加繼續經營有關之重大不確定性段落之查核報告：誠美材截至...   \n",
       "5481    MT06_高管異動                                         總經理陳聖中離職。。   \n",
       "6235    MC03_工安議題  1.華孚科技之大陸子公司昆山漢鼎精密金屬有限公司於今日上午於CNC車間西北側因不明原因發生爆...   \n",
       "6486    MT06_高管異動                               總經理郭俊良離職。。發言人郭俊良離職。。   \n",
       "\n",
       "                content_tokenized  \n",
       "個股代號                               \n",
       "1218      發言 人 林俐婉 內部 調動 由 江巍峰 接任  \n",
       "1503  內部 稽核 主管 林志強 內部 調動 由 莊文清 接任  \n",
       "1504     會計 主管 藍俊雄 內部 調動 由 林鴻名 接任  \n",
       "1709  內部 稽核 主管 游本 詮內部 調動 由 曾筱茜 接任  \n",
       "1721     財務 經理 洪廷宜 內部 調動 由 王婷渝 接任  \n",
       "...                           ...  \n",
       "4726                          NaN  \n",
       "4960                          NaN  \n",
       "5481                          NaN  \n",
       "6235                          NaN  \n",
       "6486                          NaN  \n",
       "\n",
       "[4040 rows x 8 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df['content_tokenized'] = data_df.loc[:, '事件內容'].apply(jieba_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>公司簡稱</th>\n",
       "      <th>事件日</th>\n",
       "      <th>TCRI(年/月)</th>\n",
       "      <th>事件強度</th>\n",
       "      <th>大事件類別</th>\n",
       "      <th>小事件類別</th>\n",
       "      <th>事件內容</th>\n",
       "      <th>content_tokenized</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>個股代號</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1218</th>\n",
       "      <td>泰山</td>\n",
       "      <td>20190101</td>\n",
       "      <td>6(2018/09)</td>\n",
       "      <td>0</td>\n",
       "      <td>M_經營層</td>\n",
       "      <td>MT06_高管異動</td>\n",
       "      <td>發言人林俐婉內部調動，由江巍峰接任。。</td>\n",
       "      <td>發言 人 林俐婉 內部 調動 由 江巍峰 接任</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1503</th>\n",
       "      <td>士電</td>\n",
       "      <td>20190101</td>\n",
       "      <td>4(2018/09)</td>\n",
       "      <td>0</td>\n",
       "      <td>M_經營層</td>\n",
       "      <td>MT06_高管異動</td>\n",
       "      <td>內部稽核主管林志強內部調動，由莊文清接任。。</td>\n",
       "      <td>內部 稽核 主管 林志強 內部 調動 由 莊文清 接任</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1504</th>\n",
       "      <td>東元</td>\n",
       "      <td>20190101</td>\n",
       "      <td>4(2018/09)</td>\n",
       "      <td>0</td>\n",
       "      <td>M_經營層</td>\n",
       "      <td>MT06_高管異動</td>\n",
       "      <td>會計主管藍俊雄內部調動，由林鴻名接任。。</td>\n",
       "      <td>會計 主管 藍俊雄 內部 調動 由 林鴻名 接任</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1709</th>\n",
       "      <td>和益</td>\n",
       "      <td>20190101</td>\n",
       "      <td>5(2018/09)</td>\n",
       "      <td>0</td>\n",
       "      <td>M_經營層</td>\n",
       "      <td>MT06_高管異動</td>\n",
       "      <td>內部稽核主管游本詮內部調動，由曾筱茜接任。。</td>\n",
       "      <td>內部 稽核 主管 游本 詮內部 調動 由 曾筱茜 接任</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1721</th>\n",
       "      <td>三晃</td>\n",
       "      <td>20190101</td>\n",
       "      <td>7(2018/09)</td>\n",
       "      <td>0</td>\n",
       "      <td>M_經營層</td>\n",
       "      <td>MT06_高管異動</td>\n",
       "      <td>財務經理洪廷宜內部調動，由王婷渝接任。。</td>\n",
       "      <td>財務 經理 洪廷宜 內部 調動 由 王婷渝 接任</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4726</th>\n",
       "      <td>永昕</td>\n",
       "      <td>20190331</td>\n",
       "      <td>7(2018/09)</td>\n",
       "      <td>-1</td>\n",
       "      <td>M_經營層</td>\n",
       "      <td>MT06_高管異動</td>\n",
       "      <td>財務經理陳炯祥離職。。發言人陳炯祥離職。。會計主管陳炯祥離職。。</td>\n",
       "      <td>財務 經理 陳 炯祥 離職 發言 人 陳 炯祥 離職 會計 主管 陳 炯祥 離職</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4960</th>\n",
       "      <td>誠美材</td>\n",
       "      <td>20190331</td>\n",
       "      <td>D(2019/03)</td>\n",
       "      <td>-2</td>\n",
       "      <td>A_會計/財報分析</td>\n",
       "      <td>AF09_非無保留意見</td>\n",
       "      <td>誠美材 2018年度會計師出具保留意見加繼續經營有關之重大不確定性段落之查核報告：誠美材截至...</td>\n",
       "      <td>誠美 材 2018 年度 會 計師 出具 保留 意 見加 繼續 經營 有關 之 重大 不確 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5481</th>\n",
       "      <td>新華</td>\n",
       "      <td>20190331</td>\n",
       "      <td>8(2018/09)</td>\n",
       "      <td>-1</td>\n",
       "      <td>M_經營層</td>\n",
       "      <td>MT06_高管異動</td>\n",
       "      <td>總經理陳聖中離職。。</td>\n",
       "      <td>總 經理 陳聖 中 離職</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6235</th>\n",
       "      <td>華孚</td>\n",
       "      <td>20190331</td>\n",
       "      <td>6(2018/09)</td>\n",
       "      <td>-2</td>\n",
       "      <td>M_經營層</td>\n",
       "      <td>MC03_工安議題</td>\n",
       "      <td>1.華孚科技之大陸子公司昆山漢鼎精密金屬有限公司於今日上午於CNC車間西北側因不明原因發生爆...</td>\n",
       "      <td>1. 華孚 科技 之 大陸 子公司 昆山 漢鼎 精密 金屬 有限公司 於 今日 上午 於 C...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6486</th>\n",
       "      <td>互動</td>\n",
       "      <td>20190331</td>\n",
       "      <td>6(2018/09)</td>\n",
       "      <td>-1</td>\n",
       "      <td>M_經營層</td>\n",
       "      <td>MT06_高管異動</td>\n",
       "      <td>總經理郭俊良離職。。發言人郭俊良離職。。</td>\n",
       "      <td>總 經理 郭俊良 離職 發言 人 郭俊良 離職</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4040 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                公司簡稱       事件日             TCRI(年/月)  事件強度      大事件類別  \\\n",
       "個股代號                                                                    \n",
       "1218  泰山              20190101  6(2018/09)               0      M_經營層   \n",
       "1503  士電              20190101  4(2018/09)               0      M_經營層   \n",
       "1504  東元              20190101  4(2018/09)               0      M_經營層   \n",
       "1709  和益              20190101  5(2018/09)               0      M_經營層   \n",
       "1721  三晃              20190101  7(2018/09)               0      M_經營層   \n",
       "...              ...       ...                   ...   ...        ...   \n",
       "4726  永昕              20190331  7(2018/09)              -1      M_經營層   \n",
       "4960   誠美材            20190331  D(2019/03)              -2  A_會計/財報分析   \n",
       "5481  新華              20190331  8(2018/09)              -1      M_經營層   \n",
       "6235  華孚              20190331  6(2018/09)              -2      M_經營層   \n",
       "6486  互動              20190331  6(2018/09)              -1      M_經營層   \n",
       "\n",
       "            小事件類別                                               事件內容  \\\n",
       "個股代號                                                                   \n",
       "1218    MT06_高管異動                                發言人林俐婉內部調動，由江巍峰接任。。   \n",
       "1503    MT06_高管異動                             內部稽核主管林志強內部調動，由莊文清接任。。   \n",
       "1504    MT06_高管異動                               會計主管藍俊雄內部調動，由林鴻名接任。。   \n",
       "1709    MT06_高管異動                             內部稽核主管游本詮內部調動，由曾筱茜接任。。   \n",
       "1721    MT06_高管異動                               財務經理洪廷宜內部調動，由王婷渝接任。。   \n",
       "...           ...                                                ...   \n",
       "4726    MT06_高管異動                   財務經理陳炯祥離職。。發言人陳炯祥離職。。會計主管陳炯祥離職。。   \n",
       "4960  AF09_非無保留意見  誠美材 2018年度會計師出具保留意見加繼續經營有關之重大不確定性段落之查核報告：誠美材截至...   \n",
       "5481    MT06_高管異動                                         總經理陳聖中離職。。   \n",
       "6235    MC03_工安議題  1.華孚科技之大陸子公司昆山漢鼎精密金屬有限公司於今日上午於CNC車間西北側因不明原因發生爆...   \n",
       "6486    MT06_高管異動                               總經理郭俊良離職。。發言人郭俊良離職。。   \n",
       "\n",
       "                                      content_tokenized  \n",
       "個股代號                                                     \n",
       "1218                            發言 人 林俐婉 內部 調動 由 江巍峰 接任  \n",
       "1503                        內部 稽核 主管 林志強 內部 調動 由 莊文清 接任  \n",
       "1504                           會計 主管 藍俊雄 內部 調動 由 林鴻名 接任  \n",
       "1709                        內部 稽核 主管 游本 詮內部 調動 由 曾筱茜 接任  \n",
       "1721                           財務 經理 洪廷宜 內部 調動 由 王婷渝 接任  \n",
       "...                                                 ...  \n",
       "4726           財務 經理 陳 炯祥 離職 發言 人 陳 炯祥 離職 會計 主管 陳 炯祥 離職  \n",
       "4960  誠美 材 2018 年度 會 計師 出具 保留 意 見加 繼續 經營 有關 之 重大 不確 ...  \n",
       "5481                                       總 經理 陳聖 中 離職  \n",
       "6235  1. 華孚 科技 之 大陸 子公司 昆山 漢鼎 精密 金屬 有限公司 於 今日 上午 於 C...  \n",
       "6486                            總 經理 郭俊良 離職 發言 人 郭俊良 離職  \n",
       "\n",
       "[4040 rows x 8 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_df['big_tokenized'] = data_df.loc[:, '大事件類別'].apply(jieba_tokenizer)\n",
    "#data_df['small_tokenized'] = data_df.loc[:, '小事件類別'].apply(jieba_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "MAX_NUM_WORDS = 10000\n",
    "tokenizer = keras .preprocessing.text.Tokenizer(num_words=MAX_NUM_WORDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = data_df.content_tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.fit_on_texts(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = tokenizer.texts_to_sequences(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4040"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[229, 43, 9897, 41, 57, 27, 9898, 45]]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['發言', '人', '林俐婉', '內部', '調動', '由', '江巍峰', '接任']\n"
     ]
    }
   ],
   "source": [
    "for seq in x_train[:1]:\n",
    "    print([tokenizer.index_word[idx] for idx in seq])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 [229, 43, 9897, 41, 57]  ...\n",
      "9 [41, 216, 73, 9899, 41]  ...\n",
      "8 [227, 73, 9901, 41, 57]  ...\n",
      "9 [41, 216, 73, 6865, 6866]  ...\n",
      "8 [81, 95, 9903, 41, 57]  ...\n",
      "8 [260, 73, 9905, 41, 57]  ...\n",
      "12 [1688, 6868, 9907, 136, 27]  ...\n",
      "18 [245, 10, 86, 12, 9908]  ...\n",
      "9 [246, 10, 86, 130, 12]  ...\n",
      "8 [68, 95, 6871, 41, 57]  ...\n",
      "8 [68, 95, 5518, 41, 57]  ...\n",
      "261 [2380, 738, 1085, 778, 42]  ...\n",
      "21 [245, 10, 86, 12, 9937]  ...\n",
      "10 [227, 73, 9939, 41, 57]  ...\n",
      "8 [81, 95, 9941, 41, 57]  ...\n",
      "8 [227, 73, 9943, 41, 57]  ...\n",
      "8 [68, 95, 9945, 41, 57]  ...\n",
      "8 [260, 73, 9947, 41, 57]  ...\n",
      "8 [68, 95, 9949, 41, 57]  ...\n",
      "8 [68, 95, 9951, 41, 57]  ...\n"
     ]
    }
   ],
   "source": [
    "for seq in x_train[:20]:\n",
    "    print(len(seq), seq[:5], ' ...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1459"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_seq_len = max([\n",
    "    len(seq) for seq in x_train])\n",
    "max_seq_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_SEQUENCE_LENGTH = 1000\n",
    "x_train = keras .preprocessing .sequence .pad_sequences(x1_train, maxlen=MAX_SEQUENCE_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,  229,   43, 9897,   41,   57,   27, 9898,   45],\n",
       "      dtype=int32)"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   0,    0,    0, ...,   27, 9898,   45],\n",
       "       [   0,    0,    0, ...,   27, 9900,   45],\n",
       "       [   0,    0,    0, ...,   27, 9902,   45],\n",
       "       [   0,    0,    0, ...,   27, 6867,   45],\n",
       "       [   0,    0,    0, ...,   27, 9904,   45]], dtype=int32)"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.asarray(data_df[\"事件強度\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.asarray(pd.get_dummies(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1    2386\n",
       " 0    1242\n",
       " 1     299\n",
       "-2      80\n",
       "-3      32\n",
       " 3       1\n",
       "Name: 事件強度, dtype: int64"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df[\"事件強度\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct our model\n",
    "from keras import models\n",
    "from keras import layers\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(150, activation='relu'))\n",
    "model.add(layers.Dropout(0.6))\n",
    "model.add(layers.Dense(150, activation='relu'))\n",
    "model.add(layers.Dropout(0.6))\n",
    "model.add(layers.Dense(150, activation='relu'))\n",
    "model.add(layers.Dropout(0.6))\n",
    "model.add(layers.Dense(150, activation='relu'))\n",
    "model.add(layers.Dropout(0.2))\n",
    "model.add(layers.Dense(6, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Large dropout rate: 0.6 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "WARNING:tensorflow:Large dropout rate: 0.6 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "WARNING:tensorflow:Large dropout rate: 0.6 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "Train on 3232 samples, validate on 808 samples\n",
      "Epoch 1/200\n",
      "3232/3232 [==============================] - 1s 273us/step - loss: 293.0511 - accuracy: 0.4462 - val_loss: 63.1042 - val_accuracy: 0.4455\n",
      "Epoch 2/200\n",
      "3232/3232 [==============================] - 0s 115us/step - loss: 107.9538 - accuracy: 0.5059 - val_loss: 35.9694 - val_accuracy: 0.4641\n",
      "Epoch 3/200\n",
      "3232/3232 [==============================] - 0s 105us/step - loss: 66.8158 - accuracy: 0.5322 - val_loss: 25.4547 - val_accuracy: 0.4691\n",
      "Epoch 4/200\n",
      "3232/3232 [==============================] - 0s 118us/step - loss: 56.0370 - accuracy: 0.5288 - val_loss: 18.9895 - val_accuracy: 0.4790\n",
      "Epoch 5/200\n",
      "3232/3232 [==============================] - 0s 110us/step - loss: 42.0511 - accuracy: 0.5374 - val_loss: 13.7074 - val_accuracy: 0.4579\n",
      "Epoch 6/200\n",
      "3232/3232 [==============================] - 0s 123us/step - loss: 35.4999 - accuracy: 0.5418 - val_loss: 11.4728 - val_accuracy: 0.4765\n",
      "Epoch 7/200\n",
      "3232/3232 [==============================] - 0s 115us/step - loss: 27.1348 - accuracy: 0.5702 - val_loss: 9.0224 - val_accuracy: 0.4864\n",
      "Epoch 8/200\n",
      "3232/3232 [==============================] - 0s 106us/step - loss: 22.9787 - accuracy: 0.5492 - val_loss: 7.7725 - val_accuracy: 0.4777\n",
      "Epoch 9/200\n",
      "3232/3232 [==============================] - 0s 119us/step - loss: 20.2611 - accuracy: 0.5498 - val_loss: 6.2358 - val_accuracy: 0.4666\n",
      "Epoch 10/200\n",
      "3232/3232 [==============================] - 0s 103us/step - loss: 16.9676 - accuracy: 0.5690 - val_loss: 5.8131 - val_accuracy: 0.4418\n",
      "Epoch 11/200\n",
      "3232/3232 [==============================] - 0s 108us/step - loss: 12.9502 - accuracy: 0.5866 - val_loss: 5.1835 - val_accuracy: 0.4455\n",
      "Epoch 12/200\n",
      "3232/3232 [==============================] - 0s 122us/step - loss: 11.2826 - accuracy: 0.5767 - val_loss: 4.7204 - val_accuracy: 0.4480\n",
      "Epoch 13/200\n",
      "3232/3232 [==============================] - 0s 106us/step - loss: 10.5003 - accuracy: 0.5752 - val_loss: 5.6034 - val_accuracy: 0.4505\n",
      "Epoch 14/200\n",
      "3232/3232 [==============================] - 0s 123us/step - loss: 8.6532 - accuracy: 0.6002 - val_loss: 4.0227 - val_accuracy: 0.4270\n",
      "Epoch 15/200\n",
      "3232/3232 [==============================] - 0s 113us/step - loss: 6.9340 - accuracy: 0.5990 - val_loss: 3.5135 - val_accuracy: 0.4233\n",
      "Epoch 16/200\n",
      "3232/3232 [==============================] - 0s 116us/step - loss: 7.0600 - accuracy: 0.5826 - val_loss: 3.2080 - val_accuracy: 0.4307\n",
      "Epoch 17/200\n",
      "3232/3232 [==============================] - 0s 123us/step - loss: 5.7989 - accuracy: 0.5913 - val_loss: 3.0558 - val_accuracy: 0.4220\n",
      "Epoch 18/200\n",
      "3232/3232 [==============================] - 0s 122us/step - loss: 4.7859 - accuracy: 0.6170 - val_loss: 2.7272 - val_accuracy: 0.4245\n",
      "Epoch 19/200\n",
      "3232/3232 [==============================] - 0s 130us/step - loss: 5.2126 - accuracy: 0.6095 - val_loss: 2.7364 - val_accuracy: 0.4146\n",
      "Epoch 20/200\n",
      "3232/3232 [==============================] - 0s 116us/step - loss: 4.1554 - accuracy: 0.6265 - val_loss: 2.5546 - val_accuracy: 0.4146\n",
      "Epoch 21/200\n",
      "3232/3232 [==============================] - 0s 124us/step - loss: 3.6012 - accuracy: 0.6377 - val_loss: 2.4525 - val_accuracy: 0.4072\n",
      "Epoch 22/200\n",
      "3232/3232 [==============================] - 0s 127us/step - loss: 3.5585 - accuracy: 0.6358 - val_loss: 2.3740 - val_accuracy: 0.3948\n",
      "Epoch 23/200\n",
      "3232/3232 [==============================] - 0s 115us/step - loss: 3.3178 - accuracy: 0.6454 - val_loss: 2.3552 - val_accuracy: 0.3886\n",
      "Epoch 24/200\n",
      "3232/3232 [==============================] - 0s 110us/step - loss: 2.8781 - accuracy: 0.6609 - val_loss: 2.3029 - val_accuracy: 0.3923\n",
      "Epoch 25/200\n",
      "3232/3232 [==============================] - 0s 125us/step - loss: 2.4602 - accuracy: 0.6637 - val_loss: 2.2468 - val_accuracy: 0.3948\n",
      "Epoch 26/200\n",
      "3232/3232 [==============================] - 0s 107us/step - loss: 2.6822 - accuracy: 0.6408 - val_loss: 2.2029 - val_accuracy: 0.3973\n",
      "Epoch 27/200\n",
      "3232/3232 [==============================] - 0s 138us/step - loss: 2.7260 - accuracy: 0.6448 - val_loss: 2.2554 - val_accuracy: 0.3738\n",
      "Epoch 28/200\n",
      "3232/3232 [==============================] - 0s 119us/step - loss: 2.4670 - accuracy: 0.6550 - val_loss: 2.1559 - val_accuracy: 0.3861\n",
      "Epoch 29/200\n",
      "3232/3232 [==============================] - 0s 136us/step - loss: 2.3646 - accuracy: 0.6535 - val_loss: 2.1059 - val_accuracy: 0.3614\n",
      "Epoch 30/200\n",
      "3232/3232 [==============================] - 0s 125us/step - loss: 2.1337 - accuracy: 0.6668 - val_loss: 2.1496 - val_accuracy: 0.3453\n",
      "Epoch 31/200\n",
      "3232/3232 [==============================] - 0s 124us/step - loss: 1.7963 - accuracy: 0.6597 - val_loss: 2.1486 - val_accuracy: 0.3725\n",
      "Epoch 32/200\n",
      "3232/3232 [==============================] - 0s 106us/step - loss: 1.9800 - accuracy: 0.6606 - val_loss: 2.1903 - val_accuracy: 0.3663\n",
      "Epoch 33/200\n",
      "3232/3232 [==============================] - 0s 110us/step - loss: 1.7427 - accuracy: 0.6739 - val_loss: 2.0358 - val_accuracy: 0.3255\n",
      "Epoch 34/200\n",
      "3232/3232 [==============================] - 0s 111us/step - loss: 1.8537 - accuracy: 0.6711 - val_loss: 1.9365 - val_accuracy: 0.3564\n",
      "Epoch 35/200\n",
      "3232/3232 [==============================] - 0s 120us/step - loss: 2.0190 - accuracy: 0.6646 - val_loss: 1.9409 - val_accuracy: 0.3280\n",
      "Epoch 36/200\n",
      "3232/3232 [==============================] - 0s 109us/step - loss: 2.3427 - accuracy: 0.6541 - val_loss: 2.0337 - val_accuracy: 0.3020\n",
      "Epoch 37/200\n",
      "3232/3232 [==============================] - 0s 123us/step - loss: 1.3637 - accuracy: 0.6668 - val_loss: 1.9748 - val_accuracy: 0.3057\n",
      "Epoch 38/200\n",
      "3232/3232 [==============================] - 0s 120us/step - loss: 1.7083 - accuracy: 0.6631 - val_loss: 2.0618 - val_accuracy: 0.3007\n",
      "Epoch 39/200\n",
      "3232/3232 [==============================] - 0s 108us/step - loss: 1.3876 - accuracy: 0.6726 - val_loss: 2.0327 - val_accuracy: 0.3119\n",
      "Epoch 40/200\n",
      "3232/3232 [==============================] - 0s 125us/step - loss: 1.4011 - accuracy: 0.6662 - val_loss: 2.0068 - val_accuracy: 0.3007\n",
      "Epoch 41/200\n",
      "3232/3232 [==============================] - 0s 122us/step - loss: 1.2832 - accuracy: 0.6773 - val_loss: 1.9529 - val_accuracy: 0.3020\n",
      "Epoch 42/200\n",
      "3232/3232 [==============================] - 0s 117us/step - loss: 1.6342 - accuracy: 0.6655 - val_loss: 1.9417 - val_accuracy: 0.3032\n",
      "Epoch 43/200\n",
      "3232/3232 [==============================] - 0s 127us/step - loss: 2.4778 - accuracy: 0.6739 - val_loss: 2.1368 - val_accuracy: 0.2995\n",
      "Epoch 44/200\n",
      "3232/3232 [==============================] - 0s 133us/step - loss: 1.2251 - accuracy: 0.6692 - val_loss: 2.1316 - val_accuracy: 0.2946\n",
      "Epoch 45/200\n",
      "3232/3232 [==============================] - 1s 184us/step - loss: 1.4514 - accuracy: 0.6708 - val_loss: 2.0485 - val_accuracy: 0.2933\n",
      "Epoch 46/200\n",
      "3232/3232 [==============================] - 1s 173us/step - loss: 1.2471 - accuracy: 0.6692 - val_loss: 1.9894 - val_accuracy: 0.3007\n",
      "Epoch 47/200\n",
      "3232/3232 [==============================] - 1s 170us/step - loss: 1.3765 - accuracy: 0.6658 - val_loss: 2.0351 - val_accuracy: 0.2958\n",
      "Epoch 48/200\n",
      "3232/3232 [==============================] - 0s 127us/step - loss: 1.4189 - accuracy: 0.6720 - val_loss: 2.0499 - val_accuracy: 0.2921\n",
      "Epoch 49/200\n",
      "3232/3232 [==============================] - 0s 144us/step - loss: 1.5820 - accuracy: 0.6705 - val_loss: 2.0399 - val_accuracy: 0.2859\n",
      "Epoch 50/200\n",
      "3232/3232 [==============================] - 0s 114us/step - loss: 1.0758 - accuracy: 0.6711 - val_loss: 2.0142 - val_accuracy: 0.2921\n",
      "Epoch 51/200\n",
      "3232/3232 [==============================] - 0s 125us/step - loss: 1.0248 - accuracy: 0.6711 - val_loss: 1.9747 - val_accuracy: 0.2946\n",
      "Epoch 52/200\n",
      "3232/3232 [==============================] - 0s 108us/step - loss: 0.9652 - accuracy: 0.6711 - val_loss: 1.9848 - val_accuracy: 0.2896\n",
      "Epoch 53/200\n",
      "3232/3232 [==============================] - 0s 108us/step - loss: 0.9402 - accuracy: 0.6754 - val_loss: 1.9740 - val_accuracy: 0.2908\n",
      "Epoch 54/200\n",
      "3232/3232 [==============================] - 0s 123us/step - loss: 0.9272 - accuracy: 0.6757 - val_loss: 1.9532 - val_accuracy: 0.3007\n",
      "Epoch 55/200\n",
      "3232/3232 [==============================] - 0s 109us/step - loss: 1.2389 - accuracy: 0.6671 - val_loss: 1.9785 - val_accuracy: 0.2946\n",
      "Epoch 56/200\n",
      "3232/3232 [==============================] - 0s 116us/step - loss: 1.0716 - accuracy: 0.6785 - val_loss: 1.9905 - val_accuracy: 0.2933\n",
      "Epoch 57/200\n",
      "3232/3232 [==============================] - 0s 125us/step - loss: 0.9961 - accuracy: 0.6767 - val_loss: 1.9024 - val_accuracy: 0.2946\n",
      "Epoch 58/200\n",
      "3232/3232 [==============================] - 0s 109us/step - loss: 0.8863 - accuracy: 0.6742 - val_loss: 1.8560 - val_accuracy: 0.3069\n",
      "Epoch 59/200\n",
      "3232/3232 [==============================] - 0s 121us/step - loss: 1.5978 - accuracy: 0.6683 - val_loss: 1.8050 - val_accuracy: 0.3094\n",
      "Epoch 60/200\n",
      "3232/3232 [==============================] - 0s 110us/step - loss: 1.0671 - accuracy: 0.6798 - val_loss: 1.7668 - val_accuracy: 0.2958\n",
      "Epoch 61/200\n",
      "3232/3232 [==============================] - 0s 105us/step - loss: 1.2886 - accuracy: 0.6717 - val_loss: 1.7542 - val_accuracy: 0.2921\n",
      "Epoch 62/200\n",
      "3232/3232 [==============================] - 0s 132us/step - loss: 0.8692 - accuracy: 0.6770 - val_loss: 1.7263 - val_accuracy: 0.2921\n",
      "Epoch 63/200\n",
      "3232/3232 [==============================] - 0s 150us/step - loss: 0.8783 - accuracy: 0.6730 - val_loss: 1.7028 - val_accuracy: 0.2995\n",
      "Epoch 64/200\n",
      "3232/3232 [==============================] - 1s 176us/step - loss: 0.9082 - accuracy: 0.6878 - val_loss: 1.7496 - val_accuracy: 0.2933\n",
      "Epoch 65/200\n",
      "3232/3232 [==============================] - 1s 163us/step - loss: 1.0178 - accuracy: 0.6726 - val_loss: 1.7488 - val_accuracy: 0.2983\n",
      "Epoch 66/200\n",
      "3232/3232 [==============================] - 0s 147us/step - loss: 0.8589 - accuracy: 0.6791 - val_loss: 1.7734 - val_accuracy: 0.3007\n",
      "Epoch 67/200\n",
      "3232/3232 [==============================] - 0s 145us/step - loss: 0.8407 - accuracy: 0.6795 - val_loss: 1.7689 - val_accuracy: 0.2995\n",
      "Epoch 68/200\n",
      "3232/3232 [==============================] - 0s 122us/step - loss: 0.8499 - accuracy: 0.6733 - val_loss: 1.7405 - val_accuracy: 0.2995\n",
      "Epoch 69/200\n",
      "3232/3232 [==============================] - 0s 134us/step - loss: 1.1680 - accuracy: 0.6779 - val_loss: 1.7004 - val_accuracy: 0.3007\n",
      "Epoch 70/200\n",
      "3232/3232 [==============================] - 0s 113us/step - loss: 0.8901 - accuracy: 0.6798 - val_loss: 1.7451 - val_accuracy: 0.2970\n",
      "Epoch 71/200\n",
      "3232/3232 [==============================] - 0s 125us/step - loss: 0.8060 - accuracy: 0.6853 - val_loss: 1.7436 - val_accuracy: 0.2933\n",
      "Epoch 72/200\n",
      "3232/3232 [==============================] - 0s 110us/step - loss: 0.8150 - accuracy: 0.6847 - val_loss: 1.7414 - val_accuracy: 0.2946\n",
      "Epoch 73/200\n",
      "3232/3232 [==============================] - 0s 132us/step - loss: 1.2230 - accuracy: 0.6776 - val_loss: 1.7219 - val_accuracy: 0.2970\n",
      "Epoch 74/200\n",
      "3232/3232 [==============================] - 0s 115us/step - loss: 0.7902 - accuracy: 0.6819 - val_loss: 1.7397 - val_accuracy: 0.2970\n",
      "Epoch 75/200\n",
      "3232/3232 [==============================] - 0s 117us/step - loss: 0.7781 - accuracy: 0.6773 - val_loss: 1.7314 - val_accuracy: 0.2970\n",
      "Epoch 76/200\n",
      "3232/3232 [==============================] - 0s 127us/step - loss: 1.2473 - accuracy: 0.6788 - val_loss: 1.7482 - val_accuracy: 0.2983\n",
      "Epoch 77/200\n",
      "3232/3232 [==============================] - 0s 146us/step - loss: 0.7844 - accuracy: 0.6832 - val_loss: 1.7818 - val_accuracy: 0.2983\n",
      "Epoch 78/200\n",
      "3232/3232 [==============================] - 1s 170us/step - loss: 1.0165 - accuracy: 0.6847 - val_loss: 1.7014 - val_accuracy: 0.3453\n",
      "Epoch 79/200\n",
      "3232/3232 [==============================] - 0s 132us/step - loss: 0.9114 - accuracy: 0.6754 - val_loss: 1.7161 - val_accuracy: 0.3552\n",
      "Epoch 80/200\n",
      "3232/3232 [==============================] - 0s 144us/step - loss: 0.7576 - accuracy: 0.6819 - val_loss: 1.7349 - val_accuracy: 0.3342\n",
      "Epoch 81/200\n",
      "3232/3232 [==============================] - 0s 133us/step - loss: 0.9361 - accuracy: 0.6767 - val_loss: 1.9039 - val_accuracy: 0.3391\n",
      "Epoch 82/200\n",
      "3232/3232 [==============================] - 0s 122us/step - loss: 0.7514 - accuracy: 0.6897 - val_loss: 1.9286 - val_accuracy: 0.3428\n",
      "Epoch 83/200\n",
      "3232/3232 [==============================] - 0s 110us/step - loss: 0.9149 - accuracy: 0.6897 - val_loss: 1.8922 - val_accuracy: 0.3007\n",
      "Epoch 84/200\n",
      "3232/3232 [==============================] - 0s 108us/step - loss: 0.7994 - accuracy: 0.6887 - val_loss: 1.8931 - val_accuracy: 0.3045\n",
      "Epoch 85/200\n",
      "3232/3232 [==============================] - 0s 131us/step - loss: 0.7172 - accuracy: 0.6962 - val_loss: 1.8551 - val_accuracy: 0.2995\n",
      "Epoch 86/200\n",
      "3232/3232 [==============================] - 1s 163us/step - loss: 0.7815 - accuracy: 0.6863 - val_loss: 1.9003 - val_accuracy: 0.2995\n",
      "Epoch 87/200\n",
      "3232/3232 [==============================] - 0s 119us/step - loss: 0.7163 - accuracy: 0.6890 - val_loss: 1.9141 - val_accuracy: 0.3007\n",
      "Epoch 88/200\n",
      "3232/3232 [==============================] - 0s 134us/step - loss: 0.7300 - accuracy: 0.6915 - val_loss: 1.8950 - val_accuracy: 0.3144\n",
      "Epoch 89/200\n",
      "3232/3232 [==============================] - 0s 139us/step - loss: 0.6938 - accuracy: 0.6918 - val_loss: 1.8933 - val_accuracy: 0.3428\n",
      "Epoch 90/200\n",
      "3232/3232 [==============================] - 1s 159us/step - loss: 1.0049 - accuracy: 0.6955 - val_loss: 1.8742 - val_accuracy: 0.3416\n",
      "Epoch 91/200\n",
      "3232/3232 [==============================] - 0s 151us/step - loss: 0.8128 - accuracy: 0.6925 - val_loss: 1.9288 - val_accuracy: 0.3069\n",
      "Epoch 92/200\n",
      "3232/3232 [==============================] - 0s 118us/step - loss: 0.7201 - accuracy: 0.6928 - val_loss: 1.9475 - val_accuracy: 0.3366\n",
      "Epoch 93/200\n",
      "3232/3232 [==============================] - 0s 132us/step - loss: 0.7277 - accuracy: 0.6875 - val_loss: 1.9110 - val_accuracy: 0.3366\n",
      "Epoch 94/200\n",
      "3232/3232 [==============================] - 1s 158us/step - loss: 0.6873 - accuracy: 0.6928 - val_loss: 1.9186 - val_accuracy: 0.3379\n",
      "Epoch 95/200\n",
      "3232/3232 [==============================] - 0s 106us/step - loss: 0.6998 - accuracy: 0.6931 - val_loss: 1.9136 - val_accuracy: 0.3416\n",
      "Epoch 96/200\n",
      "3232/3232 [==============================] - 1s 156us/step - loss: 0.7555 - accuracy: 0.6925 - val_loss: 1.9269 - val_accuracy: 0.3391\n",
      "Epoch 97/200\n",
      "3232/3232 [==============================] - 0s 119us/step - loss: 0.6825 - accuracy: 0.6934 - val_loss: 1.9669 - val_accuracy: 0.3366\n",
      "Epoch 98/200\n",
      "3232/3232 [==============================] - 1s 166us/step - loss: 0.8491 - accuracy: 0.6853 - val_loss: 1.9253 - val_accuracy: 0.3428\n",
      "Epoch 99/200\n",
      "3232/3232 [==============================] - 0s 114us/step - loss: 0.7006 - accuracy: 0.6949 - val_loss: 1.9355 - val_accuracy: 0.3515\n",
      "Epoch 100/200\n",
      "3232/3232 [==============================] - 0s 134us/step - loss: 0.7815 - accuracy: 0.6952 - val_loss: 1.9034 - val_accuracy: 0.3515\n",
      "Epoch 101/200\n",
      "3232/3232 [==============================] - 0s 134us/step - loss: 0.8029 - accuracy: 0.6921 - val_loss: 1.9422 - val_accuracy: 0.3391\n",
      "Epoch 102/200\n",
      "3232/3232 [==============================] - 0s 114us/step - loss: 0.6712 - accuracy: 0.6937 - val_loss: 1.9431 - val_accuracy: 0.3478\n",
      "Epoch 103/200\n",
      "3232/3232 [==============================] - 0s 128us/step - loss: 0.6677 - accuracy: 0.6977 - val_loss: 1.9058 - val_accuracy: 0.3552\n",
      "Epoch 104/200\n",
      "3232/3232 [==============================] - 0s 138us/step - loss: 0.8519 - accuracy: 0.6971 - val_loss: 1.8506 - val_accuracy: 0.3663\n",
      "Epoch 105/200\n",
      "3232/3232 [==============================] - 0s 129us/step - loss: 0.7095 - accuracy: 0.6909 - val_loss: 1.8369 - val_accuracy: 0.3713\n",
      "Epoch 106/200\n",
      "3232/3232 [==============================] - 0s 120us/step - loss: 0.7022 - accuracy: 0.6928 - val_loss: 1.8861 - val_accuracy: 0.3601\n",
      "Epoch 107/200\n",
      "3232/3232 [==============================] - 0s 122us/step - loss: 0.6946 - accuracy: 0.6928 - val_loss: 1.8847 - val_accuracy: 0.3601\n",
      "Epoch 108/200\n",
      "3232/3232 [==============================] - 0s 142us/step - loss: 0.9322 - accuracy: 0.6971 - val_loss: 1.8221 - val_accuracy: 0.3527\n",
      "Epoch 109/200\n",
      "3232/3232 [==============================] - 0s 110us/step - loss: 0.6607 - accuracy: 0.7030 - val_loss: 1.7963 - val_accuracy: 0.3527\n",
      "Epoch 110/200\n",
      "3232/3232 [==============================] - 0s 133us/step - loss: 0.6859 - accuracy: 0.6999 - val_loss: 1.7817 - val_accuracy: 0.3465\n",
      "Epoch 111/200\n",
      "3232/3232 [==============================] - 0s 124us/step - loss: 0.8280 - accuracy: 0.7020 - val_loss: 1.7535 - val_accuracy: 0.3515\n",
      "Epoch 112/200\n",
      "3232/3232 [==============================] - 0s 117us/step - loss: 0.7868 - accuracy: 0.6785 - val_loss: 1.7300 - val_accuracy: 0.3911\n",
      "Epoch 113/200\n",
      "3232/3232 [==============================] - 0s 138us/step - loss: 0.6894 - accuracy: 0.6829 - val_loss: 1.7909 - val_accuracy: 0.3750\n",
      "Epoch 114/200\n",
      "3232/3232 [==============================] - 0s 117us/step - loss: 0.6739 - accuracy: 0.6955 - val_loss: 1.8024 - val_accuracy: 0.3725\n",
      "Epoch 115/200\n",
      "3232/3232 [==============================] - 0s 137us/step - loss: 0.6767 - accuracy: 0.6989 - val_loss: 2.6091 - val_accuracy: 0.3688\n",
      "Epoch 116/200\n",
      "3232/3232 [==============================] - 0s 141us/step - loss: 0.7077 - accuracy: 0.6946 - val_loss: 2.8413 - val_accuracy: 0.3626\n",
      "Epoch 117/200\n",
      "3232/3232 [==============================] - 0s 142us/step - loss: 0.6701 - accuracy: 0.6977 - val_loss: 2.8669 - val_accuracy: 0.3676\n",
      "Epoch 118/200\n",
      "3232/3232 [==============================] - 0s 152us/step - loss: 0.6739 - accuracy: 0.7024 - val_loss: 2.9088 - val_accuracy: 0.3626\n",
      "Epoch 119/200\n",
      "3232/3232 [==============================] - 1s 225us/step - loss: 0.6722 - accuracy: 0.7061 - val_loss: 2.9023 - val_accuracy: 0.3626\n",
      "Epoch 120/200\n",
      "3232/3232 [==============================] - 1s 171us/step - loss: 0.6562 - accuracy: 0.6993 - val_loss: 2.9103 - val_accuracy: 0.3676\n",
      "Epoch 121/200\n",
      "3232/3232 [==============================] - 0s 151us/step - loss: 0.6810 - accuracy: 0.6949 - val_loss: 1.8010 - val_accuracy: 0.3626\n",
      "Epoch 122/200\n",
      "3232/3232 [==============================] - 0s 94us/step - loss: 0.6612 - accuracy: 0.6986 - val_loss: 1.7920 - val_accuracy: 0.3626\n",
      "Epoch 123/200\n",
      "3232/3232 [==============================] - 0s 91us/step - loss: 0.6731 - accuracy: 0.6980 - val_loss: 1.7971 - val_accuracy: 0.3676\n",
      "Epoch 124/200\n",
      "3232/3232 [==============================] - 0s 99us/step - loss: 0.6679 - accuracy: 0.7042 - val_loss: 1.7665 - val_accuracy: 0.3651\n",
      "Epoch 125/200\n",
      "3232/3232 [==============================] - 0s 87us/step - loss: 0.7060 - accuracy: 0.6999 - val_loss: 1.7903 - val_accuracy: 0.3552\n",
      "Epoch 126/200\n",
      "3232/3232 [==============================] - 0s 87us/step - loss: 0.6664 - accuracy: 0.6999 - val_loss: 1.7985 - val_accuracy: 0.3639\n",
      "Epoch 127/200\n",
      "3232/3232 [==============================] - 0s 103us/step - loss: 0.9313 - accuracy: 0.6912 - val_loss: 1.8174 - val_accuracy: 0.3564\n",
      "Epoch 128/200\n",
      "3232/3232 [==============================] - 0s 107us/step - loss: 0.6640 - accuracy: 0.6897 - val_loss: 1.8199 - val_accuracy: 0.3651\n",
      "Epoch 129/200\n",
      "3232/3232 [==============================] - 0s 107us/step - loss: 0.6452 - accuracy: 0.6989 - val_loss: 1.8262 - val_accuracy: 0.3564\n",
      "Epoch 130/200\n",
      "3232/3232 [==============================] - 0s 98us/step - loss: 0.6498 - accuracy: 0.6989 - val_loss: 1.8145 - val_accuracy: 0.3577\n",
      "Epoch 131/200\n",
      "3232/3232 [==============================] - 0s 93us/step - loss: 0.6692 - accuracy: 0.7042 - val_loss: 1.8025 - val_accuracy: 0.3540\n",
      "Epoch 132/200\n",
      "3232/3232 [==============================] - 0s 114us/step - loss: 0.6507 - accuracy: 0.6968 - val_loss: 1.8283 - val_accuracy: 0.3490\n",
      "Epoch 133/200\n",
      "3232/3232 [==============================] - 0s 96us/step - loss: 0.6446 - accuracy: 0.7005 - val_loss: 1.8206 - val_accuracy: 0.3552\n",
      "Epoch 134/200\n",
      "3232/3232 [==============================] - 0s 130us/step - loss: 0.7112 - accuracy: 0.6996 - val_loss: 1.8266 - val_accuracy: 0.3676\n",
      "Epoch 135/200\n",
      "3232/3232 [==============================] - 0s 114us/step - loss: 0.6496 - accuracy: 0.6983 - val_loss: 1.8272 - val_accuracy: 0.3490\n",
      "Epoch 136/200\n",
      "3232/3232 [==============================] - 0s 90us/step - loss: 0.6324 - accuracy: 0.6999 - val_loss: 1.7983 - val_accuracy: 0.3577\n",
      "Epoch 137/200\n",
      "3232/3232 [==============================] - 0s 96us/step - loss: 0.6614 - accuracy: 0.6965 - val_loss: 1.7672 - val_accuracy: 0.3577\n",
      "Epoch 138/200\n",
      "3232/3232 [==============================] - 0s 96us/step - loss: 0.6476 - accuracy: 0.6971 - val_loss: 1.8091 - val_accuracy: 0.3515\n",
      "Epoch 139/200\n",
      "3232/3232 [==============================] - 1s 166us/step - loss: 0.7494 - accuracy: 0.6983 - val_loss: 1.8003 - val_accuracy: 0.3502\n",
      "Epoch 140/200\n",
      "3232/3232 [==============================] - 0s 125us/step - loss: 0.6395 - accuracy: 0.6977 - val_loss: 1.8022 - val_accuracy: 0.3502\n",
      "Epoch 141/200\n",
      "3232/3232 [==============================] - 0s 147us/step - loss: 0.6470 - accuracy: 0.7039 - val_loss: 1.8333 - val_accuracy: 0.3564\n",
      "Epoch 142/200\n",
      "3232/3232 [==============================] - 0s 128us/step - loss: 0.6078 - accuracy: 0.7011 - val_loss: 1.8493 - val_accuracy: 0.3614\n",
      "Epoch 143/200\n",
      "3232/3232 [==============================] - 0s 97us/step - loss: 0.6380 - accuracy: 0.7005 - val_loss: 1.8122 - val_accuracy: 0.3589\n",
      "Epoch 144/200\n",
      "3232/3232 [==============================] - 0s 104us/step - loss: 0.7051 - accuracy: 0.6952 - val_loss: 1.7871 - val_accuracy: 0.3478\n",
      "Epoch 145/200\n",
      "3232/3232 [==============================] - 0s 108us/step - loss: 0.6520 - accuracy: 0.6980 - val_loss: 1.8058 - val_accuracy: 0.3515\n",
      "Epoch 146/200\n",
      "3232/3232 [==============================] - 0s 106us/step - loss: 1.1487 - accuracy: 0.6937 - val_loss: 1.8846 - val_accuracy: 0.3824\n",
      "Epoch 147/200\n",
      "3232/3232 [==============================] - 0s 87us/step - loss: 0.6432 - accuracy: 0.6989 - val_loss: 1.9111 - val_accuracy: 0.3725\n",
      "Epoch 148/200\n",
      "3232/3232 [==============================] - 0s 88us/step - loss: 0.6330 - accuracy: 0.7073 - val_loss: 1.9075 - val_accuracy: 0.3651\n",
      "Epoch 149/200\n",
      "3232/3232 [==============================] - 1s 168us/step - loss: 0.6348 - accuracy: 0.6900 - val_loss: 1.8654 - val_accuracy: 0.3713\n",
      "Epoch 150/200\n",
      "3232/3232 [==============================] - 0s 102us/step - loss: 0.6291 - accuracy: 0.7042 - val_loss: 1.8923 - val_accuracy: 0.3700\n",
      "Epoch 151/200\n",
      "3232/3232 [==============================] - 1s 166us/step - loss: 0.6358 - accuracy: 0.7036 - val_loss: 1.8769 - val_accuracy: 0.3700\n",
      "Epoch 152/200\n",
      "3232/3232 [==============================] - 1s 177us/step - loss: 0.6433 - accuracy: 0.6980 - val_loss: 1.8582 - val_accuracy: 0.3750\n",
      "Epoch 153/200\n",
      "3232/3232 [==============================] - 1s 172us/step - loss: 0.6519 - accuracy: 0.6962 - val_loss: 1.8851 - val_accuracy: 0.3626\n",
      "Epoch 154/200\n",
      "3232/3232 [==============================] - 1s 203us/step - loss: 0.7485 - accuracy: 0.6980 - val_loss: 1.9373 - val_accuracy: 0.3601\n",
      "Epoch 155/200\n",
      "3232/3232 [==============================] - 1s 206us/step - loss: 0.6275 - accuracy: 0.6884 - val_loss: 1.9244 - val_accuracy: 0.3614\n",
      "Epoch 156/200\n",
      "3232/3232 [==============================] - 1s 200us/step - loss: 0.6371 - accuracy: 0.6928 - val_loss: 1.9848 - val_accuracy: 0.3589\n",
      "Epoch 157/200\n",
      "3232/3232 [==============================] - 1s 193us/step - loss: 0.6465 - accuracy: 0.6909 - val_loss: 1.9175 - val_accuracy: 0.3280\n",
      "Epoch 158/200\n",
      "3232/3232 [==============================] - 1s 186us/step - loss: 0.6381 - accuracy: 0.6921 - val_loss: 1.8893 - val_accuracy: 0.3614\n",
      "Epoch 159/200\n",
      "3232/3232 [==============================] - 1s 191us/step - loss: 0.6335 - accuracy: 0.6971 - val_loss: 1.8887 - val_accuracy: 0.3626\n",
      "Epoch 160/200\n",
      "3232/3232 [==============================] - 1s 226us/step - loss: 0.6524 - accuracy: 0.6875 - val_loss: 1.8777 - val_accuracy: 0.3725\n",
      "Epoch 161/200\n",
      "3232/3232 [==============================] - 1s 184us/step - loss: 0.6229 - accuracy: 0.6940 - val_loss: 1.8475 - val_accuracy: 0.3713\n",
      "Epoch 162/200\n",
      "3232/3232 [==============================] - 1s 175us/step - loss: 0.6360 - accuracy: 0.6928 - val_loss: 1.8564 - val_accuracy: 0.3738\n",
      "Epoch 163/200\n",
      "3232/3232 [==============================] - 1s 162us/step - loss: 0.6250 - accuracy: 0.6943 - val_loss: 1.8604 - val_accuracy: 0.3676\n",
      "Epoch 164/200\n",
      "3232/3232 [==============================] - 0s 150us/step - loss: 0.6234 - accuracy: 0.6900 - val_loss: 1.8982 - val_accuracy: 0.3663\n",
      "Epoch 165/200\n",
      "3232/3232 [==============================] - 1s 170us/step - loss: 0.6190 - accuracy: 0.6897 - val_loss: 1.8674 - val_accuracy: 0.3676\n",
      "Epoch 166/200\n",
      "3232/3232 [==============================] - 1s 164us/step - loss: 0.6218 - accuracy: 0.6894 - val_loss: 1.8915 - val_accuracy: 0.3639\n",
      "Epoch 167/200\n",
      "3232/3232 [==============================] - 0s 133us/step - loss: 0.6227 - accuracy: 0.6946 - val_loss: 1.8812 - val_accuracy: 0.3342\n",
      "Epoch 168/200\n",
      "3232/3232 [==============================] - 0s 144us/step - loss: 0.6145 - accuracy: 0.6912 - val_loss: 1.8933 - val_accuracy: 0.3738\n",
      "Epoch 169/200\n",
      "3232/3232 [==============================] - 0s 141us/step - loss: 0.6204 - accuracy: 0.6909 - val_loss: 1.9388 - val_accuracy: 0.3304\n",
      "Epoch 170/200\n",
      "3232/3232 [==============================] - 0s 121us/step - loss: 0.6024 - accuracy: 0.6832 - val_loss: 1.9792 - val_accuracy: 0.3614\n",
      "Epoch 171/200\n",
      "3232/3232 [==============================] - 1s 155us/step - loss: 0.6266 - accuracy: 0.6931 - val_loss: 1.9560 - val_accuracy: 0.3626\n",
      "Epoch 172/200\n",
      "3232/3232 [==============================] - 0s 126us/step - loss: 0.6418 - accuracy: 0.6931 - val_loss: 1.8155 - val_accuracy: 0.3738\n",
      "Epoch 173/200\n",
      "3232/3232 [==============================] - 1s 155us/step - loss: 0.6568 - accuracy: 0.6825 - val_loss: 1.8021 - val_accuracy: 0.3688\n",
      "Epoch 174/200\n",
      "3232/3232 [==============================] - 0s 133us/step - loss: 0.6279 - accuracy: 0.6897 - val_loss: 1.8493 - val_accuracy: 0.3564\n",
      "Epoch 175/200\n",
      "3232/3232 [==============================] - 0s 142us/step - loss: 0.6347 - accuracy: 0.6928 - val_loss: 1.8606 - val_accuracy: 0.3663\n",
      "Epoch 176/200\n",
      "3232/3232 [==============================] - 0s 125us/step - loss: 0.6165 - accuracy: 0.6881 - val_loss: 1.8453 - val_accuracy: 0.3676\n",
      "Epoch 177/200\n",
      "3232/3232 [==============================] - 0s 136us/step - loss: 0.6099 - accuracy: 0.6921 - val_loss: 1.8763 - val_accuracy: 0.3651\n",
      "Epoch 178/200\n",
      "3232/3232 [==============================] - 0s 131us/step - loss: 0.6216 - accuracy: 0.6884 - val_loss: 1.8741 - val_accuracy: 0.3304\n",
      "Epoch 179/200\n",
      "3232/3232 [==============================] - 0s 127us/step - loss: 0.6121 - accuracy: 0.6965 - val_loss: 1.8769 - val_accuracy: 0.3639\n",
      "Epoch 180/200\n",
      "3232/3232 [==============================] - 0s 145us/step - loss: 0.6001 - accuracy: 0.7008 - val_loss: 1.8717 - val_accuracy: 0.3614\n",
      "Epoch 181/200\n",
      "3232/3232 [==============================] - 0s 126us/step - loss: 0.6081 - accuracy: 0.6934 - val_loss: 1.8836 - val_accuracy: 0.3651\n",
      "Epoch 182/200\n",
      "3232/3232 [==============================] - 0s 145us/step - loss: 0.6122 - accuracy: 0.7039 - val_loss: 1.8289 - val_accuracy: 0.3651\n",
      "Epoch 183/200\n",
      "3232/3232 [==============================] - 0s 130us/step - loss: 0.6149 - accuracy: 0.7027 - val_loss: 1.8673 - val_accuracy: 0.3713\n",
      "Epoch 184/200\n",
      "3232/3232 [==============================] - 1s 160us/step - loss: 0.6245 - accuracy: 0.6999 - val_loss: 1.8597 - val_accuracy: 0.3601\n",
      "Epoch 185/200\n",
      "3232/3232 [==============================] - 1s 170us/step - loss: 0.6291 - accuracy: 0.6980 - val_loss: 1.9293 - val_accuracy: 0.3614\n",
      "Epoch 186/200\n",
      "3232/3232 [==============================] - 1s 173us/step - loss: 0.7946 - accuracy: 0.6925 - val_loss: 1.8581 - val_accuracy: 0.3193\n",
      "Epoch 187/200\n",
      "3232/3232 [==============================] - 1s 155us/step - loss: 0.7371 - accuracy: 0.6934 - val_loss: 1.8072 - val_accuracy: 0.3688\n",
      "Epoch 188/200\n",
      "3232/3232 [==============================] - 1s 166us/step - loss: 0.6078 - accuracy: 0.7104 - val_loss: 1.7721 - val_accuracy: 0.3750\n",
      "Epoch 189/200\n",
      "3232/3232 [==============================] - 0s 132us/step - loss: 0.6822 - accuracy: 0.6943 - val_loss: 1.8112 - val_accuracy: 0.4876\n",
      "Epoch 190/200\n",
      "3232/3232 [==============================] - 0s 154us/step - loss: 0.6672 - accuracy: 0.7085 - val_loss: 1.9443 - val_accuracy: 0.3775\n",
      "Epoch 191/200\n",
      "3232/3232 [==============================] - 0s 126us/step - loss: 0.6132 - accuracy: 0.6925 - val_loss: 1.9473 - val_accuracy: 0.3824\n",
      "Epoch 192/200\n",
      "3232/3232 [==============================] - 1s 171us/step - loss: 0.7288 - accuracy: 0.6925 - val_loss: 1.8296 - val_accuracy: 0.4938\n",
      "Epoch 193/200\n",
      "3232/3232 [==============================] - 0s 145us/step - loss: 0.6257 - accuracy: 0.6921 - val_loss: 1.8926 - val_accuracy: 0.3849\n",
      "Epoch 194/200\n",
      "3232/3232 [==============================] - 1s 159us/step - loss: 0.6442 - accuracy: 0.6931 - val_loss: 1.8832 - val_accuracy: 0.3787\n",
      "Epoch 195/200\n",
      "3232/3232 [==============================] - 1s 210us/step - loss: 0.6113 - accuracy: 0.6974 - val_loss: 1.8829 - val_accuracy: 0.3787\n",
      "Epoch 196/200\n",
      "2700/3232 [========================>.....] - ETA: 0s - loss: 0.5979 - accuracy: 0.7067"
     ]
    }
   ],
   "source": [
    "# Iterate on your training data by calling the fit() method of your model\n",
    "history = model.fit(x_train,\n",
    "                    y_train,\n",
    "                    epochs=200,\n",
    "                    batch_size=100,\n",
    "                   validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the results of loss values from the training set and validtion set\n",
    "history_dict = history.history\n",
    "loss_values = history_dict['loss']\n",
    "val_loss_values = history_dict['val_loss']\n",
    "\n",
    "epochs = range(1, len(history_dict['accuracy']) + 1)\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.plot(epochs, loss_values, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss_values, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the results of accuracy from the training set and validtion set\n",
    "acc = history_dict['accuracy']\n",
    "val_acc = history_dict['val_accuracy']\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
