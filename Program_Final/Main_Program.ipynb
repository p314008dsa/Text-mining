{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-f9e716c06b5e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m             \u001b[0;31m# 切詞\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m             \u001b[0mcut\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcutword\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mckiptoken\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcut_new_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    110\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m             \u001b[0;31m# 文字向量化前處理\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/文字探勘/Program_Final_test/cutword.py\u001b[0m in \u001b[0;36mckiptoken\u001b[0;34m(pandas)\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0msentence_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdelete_punctuation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m     \u001b[0mword_sentence_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mws\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m     \u001b[0mcontent_tokenized\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mword_sentence_list\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/ckiptagger/api.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, sentence_list, recommend_dictionary, coerce_dictionary, sentence_segmentation, segment_delimiter_set, character_normalization, batch_sentences, batch_characters)\u001b[0m\n\u001b[1;32m    112\u001b[0m                 \u001b[0mparital_seq_segment_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msample\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msample_list\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m                 \u001b[0mparital_seq_segment_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_label_for_a_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mpartial_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m                 \u001b[0mseq_segment_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparital_seq_segment_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpartial_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/ckiptagger/model_ws.py\u001b[0m in \u001b[0;36mpredict_label_for_a_batch\u001b[0;34m(self, sample_list)\u001b[0m\n\u001b[1;32m    415\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_length\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0minput_length\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    416\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mw_k\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mw_k\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 417\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mw_v\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mw_v\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    418\u001b[0m             }\n\u001b[1;32m    419\u001b[0m         )\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    927\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 929\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    930\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1150\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1152\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1153\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1328\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1329\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1330\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1332\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1333\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1334\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1335\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1336\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1317\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1319\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1405\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1407\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1409\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Main Program\n",
    "\n",
    "#######################################   引入所需套件   #######################################\n",
    "import models_function as mf\n",
    "import cutword\n",
    "import pandas as pd\n",
    "import time\n",
    "import string\n",
    "from wordpress_xmlrpc import Client, WordPressPost\n",
    "from wordpress_xmlrpc.methods.users import GetUserInfo\n",
    "from wordpress_xmlrpc.methods.posts import GetPosts, NewPost\n",
    "import pymysql\n",
    "from joblib import dump, load\n",
    "\n",
    "#######################################   前置設定   #######################################\n",
    "\n",
    "# 公開資訊觀測站網址\n",
    "url2 = 'https://mops.twse.com.tw/mops/web/t05sr01_1'\n",
    "\n",
    "# load斷切詞需要的tokenizer\n",
    "my_tokenizer = load('/Users/wangyuda/Desktop/文字探勘/Program_Final_test/models_function_box/my_tokenizer.joblib')\n",
    "\n",
    "# 判斷新增新聞筆數的起始計數\n",
    "old_number = 0\n",
    "\n",
    "#######################################   登入網站   #######################################\n",
    "\n",
    "# 網站登入資訊，帳號與密碼\n",
    "id = \"p314008dsa1\"\n",
    "password = \"MaTuItgeeu30hy$D63\"\n",
    "\n",
    "# 輸入我們的WordPress網址，若試著連上該網址，應該會出現「XML-RPC server accepts POST requests only.」才對。\n",
    "url = \"http://ec2-52-87-157-212.compute-1.amazonaws.com//xmlrpc.php\"\n",
    "\n",
    "# 新文章要直接發布的話，就不用改，如果要變成草稿，就改成\"draft\"\n",
    "which = \"publish\"\n",
    "\n",
    "# 建立客戶端，登入網頁\n",
    "wp = Client(url, id, password)\n",
    "\n",
    "#######################################   設定定時循環功能 #######################################\n",
    "\n",
    "last_time = 0\n",
    "\n",
    "# 公開資訊觀測站資料約180秒更新一次，考慮程式計算時間，將循環週期設為120秒\n",
    "period = 120\n",
    "while(True):\n",
    "    if (time.time() - last_time) > period:\n",
    "        \n",
    "        #######################################   進行爬蟲  #######################################\n",
    "        \n",
    "        # 讀取網站資料\n",
    "        page = pd.read_html(url2)[7]\n",
    "        new_number = len(page)\n",
    "        \n",
    "        #######################################   判斷新增新聞筆數   #######################################\n",
    "        \n",
    "        # 計算新增資料的行數 add_num\n",
    "        # 若新資料筆數增加，則讀取（新資料筆數ㄧ舊資料筆數）筆資料\n",
    "        add_num = 0\n",
    "        if new_number > old_number:\n",
    "            add_num = new_number - old_number\n",
    "            old_number = new_number\n",
    "        \n",
    "        # 若無新增資料，則跳入下一個迴圈，繼續等120秒\n",
    "        elif new_number == old_number:\n",
    "            last_time = time.time()\n",
    "            continue\n",
    "        \n",
    "        # 若新資料筆數少於舊資料筆數，代表過24點資料歸零\n",
    "        elif new_number < old_number:\n",
    "            old_number = 0                   # 將舊資料數歸零\n",
    "            if new_number > 0:              # 若新資料數大於零，代表有新資料產生\n",
    "                add_num = new_number\n",
    "            else:                                   # 若新資料數等於零，代表無新資料\n",
    "                last_time = time.time()      # 則跳入下一個迴圈，繼續等120秒\n",
    "                continue\n",
    "                \n",
    "        else:\n",
    "            continue\n",
    "        \n",
    "        # 最新資料在最上方，為了照時間順序排列，從新增資料的行數開始往上讀\n",
    "        for i in range(add_num-1 , -1, -1):\n",
    "            \n",
    "            #######################################   整理切詞用與儲存用dataframe   #######################################\n",
    "            \n",
    "            # 讀取新資料，做後續的資料處理\n",
    "            # 包含「公司代號、公司簡稱、發言日期、發言時間、主旨」等所有資料，將存入資料庫\n",
    "            add_new = []  \n",
    "            \n",
    "            # 只包含主旨，之後用來切字\n",
    "            cut_new = []   \n",
    "            \n",
    "            # 紀錄每一筆各欄位的資料\n",
    "            add_new_col = []\n",
    "            for j in range(5):\n",
    "                add_new_col.append(page.iloc[i, j])\n",
    "\n",
    "            add_new.append(add_new_col)\n",
    "            cut_new.append(page.iloc[i, 4])\n",
    "\n",
    "            # 製作新聞各項資訊與切詞用的 dataframe\n",
    "            add_new_df = pd.DataFrame(data = add_new, columns = [\"公司代號\", \"公司簡稱\", \"發言日期\", \"發言時間\", \"主旨\"])\n",
    "            cut_new_df = pd.DataFrame(data = cut_new, columns = [\"cut_new\"])\n",
    "            \n",
    "            #######################################   進行切詞   #######################################\n",
    "            \n",
    "            # 切詞\n",
    "            cut = cutword.ckiptoken(cut_new_df)\n",
    "            \n",
    "            # 文字向量化前處理\n",
    "            cut_0 = cut.content_tokenized            \n",
    "            \n",
    "            # 文字向量化\n",
    "            token = mf.preprocess_text(my_tokenizer, cut_0)\n",
    "            \n",
    "            # 保留斷詞資料\n",
    "            cut = cut.iloc[0, 0]\n",
    "            \n",
    "            #######################################   放入模型預測   #######################################\n",
    "            \n",
    "            # 將input 輸入模型，給出預測\n",
    "            intensity = mf.predict_intensity(token)\n",
    "            big_event = mf.predict_Big_Event(token)\n",
    "            small_event = mf.predict_Small_Event(token)\n",
    "            up_or_down = mf.predict_Month_abnormal_returns(token) \n",
    "            \n",
    "            #######################################   網頁輸出   #######################################\n",
    "            \n",
    "            intensity = intensity[0][0]\n",
    "            \n",
    "            # 若事件強度絕對值大於1，則上傳到網站\n",
    "            if abs(intensity) > 1:\n",
    "                \n",
    "                # 設定輸出內容\n",
    "                title = add_new_df.iloc[0, 2] + ' ' + add_new_df.iloc[0, 1] \n",
    "                excerpt = \"事件強度：\" + str(intensity) + '\\n' + \"預期漲跌：\" +  up_or_down\n",
    "                category = str(add_new_df.iloc[0, 0]) + ' ' + str(add_new_df.iloc[0, 1])\n",
    "                content = excerpt + '\\n' + \"發言時間：\" + add_new_df.iloc[0, 3] + '\\n' + \"大事件類別：\" + big_event[0][0] + '\\n'\n",
    "                content = content + \"小事件類別：\" + small_event[0][0] + '\\n' + \"新聞內容：\" + add_new_df.iloc[0, 4]                \n",
    "                \n",
    "                # 依據讀取的資料，在部落格中建立新文章\n",
    "                post = WordPressPost()\n",
    "                post.post_status = which\n",
    "                post.excerpt = excerpt\n",
    "                post.title = title\n",
    "                post.content = content\n",
    "                post.terms_names = {\"category\": [category]}\n",
    "\n",
    "                # 發布文章\n",
    "                wp.call(NewPost(post))\n",
    "\n",
    "            #######################################   存入MySQL資料庫   #######################################\n",
    "            \n",
    "            # 連接資料庫\n",
    "            db = pymysql.connect(\"127.0.0.1\",\"root\",\"s70399S80228\",\"sys\" )\n",
    "\n",
    "            cursor = db.cursor()\n",
    "            \n",
    "            # 設定簡潔的變數名稱\n",
    "            a = int(add_new_df.iloc[0,0])\n",
    "            b = add_new_df.iloc[0,1]\n",
    "            c = add_new_df.iloc[0,2]\n",
    "            d = add_new_df.iloc[0,3]\n",
    "            e = int(intensity)\n",
    "            f = up_or_down\n",
    "            g = big_event[0][0]\n",
    "            h = small_event[0][0]\n",
    "            i = add_new_df.iloc[0,4]\n",
    "            j = cut\n",
    "\n",
    "            sql = \"\"\"INSERT INTO result_test(Stock_id, Company_name, Date ,Time,\n",
    "               Intensity, Direction, Big_event_type, Small_event_type, News_content, News_cut)\n",
    "               VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s)\"\"\"\n",
    "\n",
    "            try:\n",
    "                # Execute the SQL command\n",
    "                cursor.execute(sql, (a, b, c, d, e, f, g, h, i, j))\n",
    "                # Commit your changes in the database\n",
    "                db.commit()\n",
    "            except:\n",
    "                # Rollback in case there is any error\n",
    "                db.rollback()\n",
    "                \n",
    "        #######################################   流程結束，等待下一次爬蟲   #######################################\n",
    "        \n",
    "        last_time = time.time()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "old_number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
